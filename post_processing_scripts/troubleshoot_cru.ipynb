{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a335da-1ccc-488a-8d94-86bc82a15326",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "#import optshrink as opt # package we create\n",
    "import numpy as np\n",
    "# import scipy.io as sio\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gp\n",
    "from geodatasets import get_path\n",
    "from shapely.geometry import Polygon\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5e9d51-b8f1-454c-af53-846a81c957af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_col_names = ['lon'\n",
    ",'lat'\n",
    ",'variable'\n",
    ",'cohort_number'\n",
    ",'stand_age'\n",
    ",'potential_veg'\n",
    ",'current_veg'\n",
    ",'community_type'\n",
    ",'subtype'\n",
    ",'silt_clay'  ###check this order\n",
    ",'lc_state'\n",
    ",'land_area'\n",
    ",'cohort_area'\n",
    ",'year'\n",
    ",'annual_sum'\n",
    ",'monthly_maximum'\n",
    ",'monthly_mean'\n",
    ",'monthly_minimum'\n",
    ",'Jan'\n",
    ",'Feb'\n",
    ",'Mar'\n",
    ",'Apr'\n",
    ",'May'\n",
    ",'Jun'\n",
    ",'Jul'\n",
    ",'Aug'\n",
    ",'Sep'\n",
    ",'Oct'\n",
    ",'Nov'\n",
    ",'Dec'\n",
    ",'region']\n",
    "\n",
    "\n",
    "\n",
    "forest_vegs = [4, 5, 6, 8, 9, 10, 11, 16, 17, 18, 19, 20, 25, 33]\n",
    "forest_types = [\"Boreal Forest\", \"Forested Boreal Wetlands\", \"Boreal Woodlands\",\"Mixed Temperate Forests\", \n",
    "               \"Temperate Coniferous Forests\", \"Temperate Deciduous Forests\", \"Temperate Forested Wetlands\", \n",
    "               \"Tropical Evergreen Forests\", \"Tropical Forested Wetlands\", \"Tropical Deciduous Forests\", \"Xeromorphic Forests and Woodlands\"\n",
    "               ,\"Tropical Forested Floodplains\", \"Temperate Forested Floodplains\", \"Temperate Broadleaved Evergreen Forests\"]\n",
    "\n",
    "forest_pfts = pd.DataFrame({\n",
    "'current_veg':forest_vegs, \n",
    "    'forest_type':forest_types\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50686835-2e0a-4fd8-ad18-66570685a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensemble_dir = '/group/moniergrp/TEM_Large_Ensemble/run_support_files/cru_regions/'\n",
    "\n",
    "output_dir_path = '/group/moniergrp/TEM_Large_Ensemble/output_files/cru_historical/' \n",
    "intervals_standage = np.concatenate((np.arange(-1, 100, 5),np.array([124, 149, 3000])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0564403b-c09f-49fe-8c8a-4d43ebf1dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'region_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678ac6d-1350-4ec2-b188-9771e13b43eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_region = pd.DataFrame()\n",
    "all_region_stand_age = pd.DataFrame()\n",
    "\n",
    "# for region in regions:\n",
    "files = os.listdir(ensemble_dir+region+'/var_out/')\n",
    "for file in files:\n",
    "    data = pd.read_csv(ensemble_dir+region+'/var_out/'+file, names = output_col_names)\n",
    "    if len(data) > 0:\n",
    "        # print(len(data))\n",
    "        data=data.merge(forest_pfts, on = 'current_veg', how = 'inner')\n",
    "        # print(len(data))\n",
    "        data['stand_age_bin'] = pd.cut(\n",
    "                    data['stand_age'], bins=intervals_standage)\n",
    "        data['stand_age_interval_min'] = data['stand_age_bin'].apply(lambda x: x.left).astype(int) + 1\n",
    "        data['file'] = file\n",
    "\n",
    "        #####create weight for variables\n",
    "        data['monthly_mean_weight'] = data['monthly_mean']* data['cohort_area']\n",
    "        data['Jan_weight'] = data['Jan']* data['cohort_area']\n",
    "        data['Feb_weight'] = data['Feb']* data['cohort_area']\n",
    "        data['Mar_weight'] = data['Mar']* data['cohort_area']\n",
    "        data['Apr_weight'] = data['Apr']* data['cohort_area']\n",
    "        data['May_weight'] = data['May']* data['cohort_area']\n",
    "        data['Jun_weight'] = data['Jun']* data['cohort_area']\n",
    "        data['Jul_weight'] = data['Jul']* data['cohort_area']\n",
    "        data['Aug_weight'] = data['Aug']* data['cohort_area']\n",
    "        data['Sep_weight'] = data['Sep']* data['cohort_area']\n",
    "        data['Oct_weight'] = data['Oct']* data['cohort_area']\n",
    "        data['Nov_weight'] = data['Nov']* data['cohort_area']\n",
    "        data['Dec_weight'] = data['Dec']* data['cohort_area']\n",
    "\n",
    "\n",
    "        #####group by stand age bin\n",
    "        data = data.groupby(\n",
    "            ['lon','lat','year','variable','stand_age_interval_min','forest_type','current_veg','community_type','silt_clay','region','file']\n",
    "        )[data.columns[data.columns.str.contains('weight|area')]\n",
    "        ].sum()\n",
    "        # ####recalculate values\n",
    "        data=data.reset_index()\n",
    "        # ### finish weighted average calculation\n",
    "        data['monthly_mean'] = (data['monthly_mean_weight']/ data['cohort_area'])\n",
    "        data['Jan'] = (data['Jan_weight']/ data['cohort_area'])\n",
    "        data['Feb'] = (data['Feb_weight']/ data['cohort_area'])\n",
    "        data['Mar'] = (data['Mar_weight']/ data['cohort_area'])\n",
    "        data['Apr'] = (data['Apr_weight']/ data['cohort_area'])\n",
    "        data['May'] = (data['May_weight']/ data['cohort_area'])\n",
    "        data['Jun'] = (data['Jun_weight']/ data['cohort_area'])\n",
    "        data['Jul'] = (data['Jul_weight']/ data['cohort_area'])\n",
    "        data['Aug'] = (data['Aug_weight']/ data['cohort_area'])\n",
    "        data['Sep'] = (data['Sep_weight']/ data['cohort_area'])\n",
    "        data['Oct'] = (data['Oct_weight']/ data['cohort_area'])\n",
    "        data['Nov'] = (data['Nov_weight']/ data['cohort_area'])\n",
    "        data['Dec'] = (data['Dec_weight']/ data['cohort_area'])\n",
    "\n",
    "        # ###give relevant information\n",
    "\n",
    "        all_region_stand_age = pd.concat([all_region_stand_age, data])\n",
    "\n",
    "        ####group by lat/lon/year\n",
    "        data = data.groupby(\n",
    "            ['lon','lat','year','variable','forest_type','current_veg','community_type','silt_clay','region','file']\n",
    "        )[data.columns[data.columns.str.contains('weight|area')]\n",
    "        ].sum()\n",
    "        # print(len(data))\n",
    "        # ###sum up by lat lon year var\n",
    "\n",
    "        # ####recalculate values\n",
    "        data=data.reset_index()\n",
    "        # ### finish weighted average calculation\n",
    "        data['monthly_mean'] = (data['monthly_mean_weight']/ data['cohort_area'])\n",
    "        data['Jan'] = (data['Jan_weight']/ data['cohort_area'])\n",
    "        data['Feb'] = (data['Feb_weight']/ data['cohort_area'])\n",
    "        data['Mar'] = (data['Mar_weight']/ data['cohort_area'])\n",
    "        data['Apr'] = (data['Apr_weight']/ data['cohort_area'])\n",
    "        data['May'] = (data['May_weight']/ data['cohort_area'])\n",
    "        data['Jun'] = (data['Jun_weight']/ data['cohort_area'])\n",
    "        data['Jul'] = (data['Jul_weight']/ data['cohort_area'])\n",
    "        data['Aug'] = (data['Aug_weight']/ data['cohort_area'])\n",
    "        data['Sep'] = (data['Sep_weight']/ data['cohort_area'])\n",
    "        data['Oct'] = (data['Oct_weight']/ data['cohort_area'])\n",
    "        data['Nov'] = (data['Nov_weight']/ data['cohort_area'])\n",
    "        data['Dec'] = (data['Dec_weight']/ data['cohort_area'])\n",
    "\n",
    "        # ###give relevant information\n",
    "\n",
    "        all_region = pd.concat([all_region, data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351f37b-38e5-41f7-bdbd-1d8695f2c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### save after region\n",
    "all_region_stand_age.to_csv(output_dir_path+region+'/lat_lon_year_standage_var_hist.csv', index=False,float_format='%.2f')\n",
    "all_region.to_csv(output_dir_path+region+'/lat_lon_year_var_hist.csv', index=False,float_format='%.2f')\n",
    "all_region['run_region'] = region\n",
    "\n",
    "all_region_area = all_region.groupby(\n",
    "    ['lon','lat','variable','forest_type','current_veg','community_type','silt_clay','region','run_region']\n",
    ")[all_region.columns[all_region.columns.str.contains('weight|area')]\n",
    "].sum()\n",
    "\n",
    "all_region_area['monthly_mean'] = (all_region_area['monthly_mean_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Jan'] = (all_region_area['Jan_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Feb'] = (all_region_area['Feb_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Mar'] = (all_region_area['Mar_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Apr'] = (all_region_area['Apr_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['May'] = (all_region_area['May_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Jun'] = (all_region_area['Jun_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Jul'] = (all_region_area['Jul_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Aug'] = (all_region_area['Aug_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Sep'] = (all_region_area['Sep_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Oct'] = (all_region_area['Oct_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Nov'] = (all_region_area['Nov_weight']/ all_region_area['cohort_area'])\n",
    "all_region_area['Dec'] = (all_region_area['Dec_weight']/ all_region_area['cohort_area'])\n",
    "\n",
    "##summarize by lat, lon, var\n",
    "all_region_area = all_region_area.reset_index()\n",
    "\n",
    "all_region_area.to_csv(output_dir_path+region+'/lat_lon_hist.csv', index=False,float_format='%.2f')\n",
    "\n",
    "\n",
    "all_region_year = all_region.groupby(\n",
    "    ['year','variable','forest_type','current_veg','community_type', 'run_region']\n",
    ")[all_region.columns[all_region.columns.str.contains('weight|area')]\n",
    "].sum()\n",
    "\n",
    "all_region_year['monthly_mean'] = (all_region_year['monthly_mean_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Jan'] = (all_region_year['Jan_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Feb'] = (all_region_year['Feb_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Mar'] = (all_region_year['Mar_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Apr'] = (all_region_year['Apr_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['May'] = (all_region_year['May_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Jun'] = (all_region_year['Jun_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Jul'] = (all_region_year['Jul_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Aug'] = (all_region_year['Aug_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Sep'] = (all_region_year['Sep_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Oct'] = (all_region_year['Oct_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Nov'] = (all_region_year['Nov_weight']/ all_region_year['cohort_area'])\n",
    "all_region_year['Dec'] = (all_region_year['Dec_weight']/ all_region_year['cohort_area'])\n",
    "\n",
    "##summarize by lat, lon, var\n",
    "all_region_year = all_region_year.reset_index()\n",
    "\n",
    "all_region_year.to_csv(output_dir_path+region+'/year_hist.csv', index=False,float_format='%.2f')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaforge",
   "language": "python",
   "name": "condaforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
