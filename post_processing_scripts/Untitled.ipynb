{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15852bc-19ee-4316-8ca8-af3051089029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import gpflow\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b0e5be7-1276-4740-a461-1134d07c5935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 5: 1, 10: 2, 15: 3, 20: 4, 25: 5, 30: 6, 35: 7, 40: 8, 45: 9, 50: 10, 55: 11, 60: 12, 65: 13, 70: 14, 75: 15, 80: 16, 85: 17, 90: 18, 95: 19, 100: 20, 125: 21, 150: 22}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    287630.000000\n",
       "mean          9.834551\n",
       "std           7.873397\n",
       "min           0.000000\n",
       "25%           3.000000\n",
       "50%           8.000000\n",
       "75%          17.000000\n",
       "max          22.000000\n",
       "Name: ordinal_stand_age, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = pd.read_csv('/home/smmrrr/TEM_Analysis/TEM_Analysis/region_3_test_model_data_conif_vegc.csv')\n",
    "unique_bins = sorted(model_data.stand_age_interval_min.unique())\n",
    "bin_to_ordinal = {bin_val: idx for idx, bin_val in (enumerate(unique_bins))}\n",
    "print(bin_to_ordinal)\n",
    "model_data['ordinal_stand_age'] = model_data['stand_age_interval_min'].map(bin_to_ordinal)\n",
    "model_data['ordinal_stand_age'].describe()\n",
    "# model_data = model_data.loc[model_data['year']>=1900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35f8b5ba-a336-49ad-899f-8431c0af1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_compare = ['monthly_mean', 'tswrf_v11', 'tmp', 'precip', 'dtr', 'vpr', 'wind','co2','Ndep_Trendy']\n",
    "\n",
    "base_comparison = model_data.loc[model_data['year'].between(1900,1950)].groupby(\n",
    "    ['lon','lat','ordinal_stand_age'])[variables_to_compare].mean().reset_index()\n",
    "\n",
    "\n",
    "model_data=model_data.merge(base_comparison, on = ['lon','lat','ordinal_stand_age'], suffixes = ('_ts', '_base'))\n",
    "model_data=model_data.loc[model_data['monthly_mean_base']!=0]\n",
    "# Iterate over the list of variables and create new columns in model_data for their ratios\n",
    "for var in variables_to_compare:\n",
    "    ts_column = f\"{var}_ts\"     # Time series data column name\n",
    "    base_column = f\"{var}_base\" # Baseline data column name\n",
    "    ratio_column = f\"{var}_ratio\" # Name for the new ratio column\n",
    "\n",
    "    # Compute the ratio and create a new column in model_data\n",
    "    if (var =='precip'):\n",
    "        model_data[ratio_column] = model_data[ts_column] / model_data[base_column]\n",
    "    else:\n",
    "        model_data[ratio_column] = model_data[ts_column] - model_data[base_column]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f71cd4e-8d70-439a-a16e-aea50fbd59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = model_data.loc[model_data['year']>=1950]\n",
    "# model_data = model_data.loc[model_data['monthly_mean_ratio']<=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cb16604-6148-46c6-a7f6-a7ed3966560e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lon', 'lat', 'year', 'stand_age_interval_min', 'silt_clay',\n",
       "       'monthly_mean_ts', 'tswrf_v11_ts', 'tmp_ts', 'precip_ts', 'dtr_ts',\n",
       "       'vpr_ts', 'wind_ts', 'Ndep_Trendy_ts', 'Nfer_crop', 'Nfer_pas', 'var',\n",
       "       'Area', 'elev', 'region', 'co2_ts', 'ordinal_stand_age',\n",
       "       'monthly_mean_base', 'tswrf_v11_base', 'tmp_base', 'precip_base',\n",
       "       'dtr_base', 'vpr_base', 'wind_base', 'co2_base', 'Ndep_Trendy_base',\n",
       "       'monthly_mean_ratio', 'tswrf_v11_ratio', 'tmp_ratio', 'precip_ratio',\n",
       "       'dtr_ratio', 'vpr_ratio', 'wind_ratio', 'co2_ratio',\n",
       "       'Ndep_Trendy_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceda3ab3-61b1-484e-92e1-82e1b41fbd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "X = np.array(model_data[['tswrf_v11_ratio', 'tmp_ratio', 'precip_ratio',\n",
    "       'dtr_ratio', 'vpr_ratio', 'wind_ratio', 'co2_ratio',\n",
    "       'Ndep_Trendy_ratio']])\n",
    "Y = np.array(model_data['monthly_mean_ratio'])\n",
    "# Y = np.sqrt(model_data['monthly_mean_ratio'])\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "# randomness can be controlled with a defined `random_state`\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "# Y = np.array(\n",
    "#     model_data.loc[:, 'monthly_mean_ratio']\n",
    "# )\n",
    "# X = np.array(\n",
    "#      # model_data.loc[model_data['year']>=2020,['ordinal_stand_age']]\n",
    "#      model_data.loc[:,['ordinal_stand_age','tmp_ratio']]\n",
    "# )\n",
    "Y = Y.reshape(len(Y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04000455-374e-4583-858f-bf4e7592b5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.39633333e+00, -7.32333333e-01,  9.74761782e-01, ...,\n",
       "         1.89666667e-01,  7.10766667e+00,  1.61782733e+02],\n",
       "       [ 3.66235294e+00, -1.07235294e+00,  1.11086551e+00, ...,\n",
       "         7.13725490e-02,  9.90470588e+00,  9.22240608e+01],\n",
       "       [-1.47650000e+00,  3.84000000e-01,  1.33339549e+00, ...,\n",
       "         6.55000000e-02,  8.72950000e+00,  1.05882280e+02],\n",
       "       ...,\n",
       "       [ 4.32137255e+00, -7.81960784e-01,  1.34725356e+00, ...,\n",
       "        -4.96862745e-01,  4.72947059e+01,  2.18011094e+02],\n",
       "       [ 1.12549020e+00,  8.86862745e-01,  7.88201217e-01, ...,\n",
       "        -3.05294118e-01,  6.73647059e+01,  3.21865792e+02],\n",
       "       [ 5.95509804e+00,  4.56078431e-01,  1.16322274e+00, ...,\n",
       "        -3.81764706e-01,  7.96347059e+01,  2.81961261e+02]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99b72087-6383-4a1a-8598-10e877b39222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(1234)\n",
    "# n_inducing = 500\n",
    "# inducing_variable = rng.choice(X, size=n_inducing, replace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947aa704-5317-457a-96d4-3337d60f8bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11160,  27901,  55802,  83703, 100444])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "# Calculate the percentiles (assuming X is sorted, if not, you need to sort it first)\n",
    "# \"percentiles\" is an array of percentiles to calculate\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "percentile_indices = np.percentile(np.arange(len(Y)), percentiles).astype(int)\n",
    "percentile_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "029930db-6452-4547-b9c0-af00e8d5b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10868.54         -713.48034938    -32.9154902     537.84726471\n",
      "   1636.28323529   2995.20815686  15387.19214286]\n",
      "[[    0    28    29 ... 78117 78120 78121]]\n",
      "[[   16    24    32 ... 78106 78108 78118]]\n",
      "[[    7     8    12 ... 78113 78116 78122]]\n",
      "[[    1     2     3 ... 78114 78115 78119]]\n",
      "[[    4     9    11 ... 78109 78111 78123]]\n",
      "[[    5    21    25 ... 78058 78062 78064]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(12345)\n",
    "bin_size = 12\n",
    "# Calculate the percentile values on Y\n",
    "percentiles = [0, 10, 25, 50, 75, 90, 100]\n",
    "percentile_values = np.percentile(Y_train, percentiles)\n",
    "print(percentile_values)\n",
    "# Initialize a list to store the indices of the subsets\n",
    "subset_indices = np.array([])\n",
    "# subset_indices= subset_indices.reshape((0, 1))\n",
    "# For each pair of percentile values, select the indices of 100 points from within that range\n",
    "for i in range(len(percentile_values) - 1):\n",
    "    # Get the value range for the current bin\n",
    "    low, high = percentile_values[i], percentile_values[i+1]\n",
    "    \n",
    "    # Find the indices where Y falls within the current percentile range \n",
    "    # Assuming Y is 1D and has the same length as the rows or columns of X\n",
    "    in_range_indices = np.array(np.where((Y_train >= low) & (Y_train < high)))\n",
    "    print(in_range_indices)\n",
    "    in_range_indices=in_range_indices.reshape(in_range_indices.shape[1],1)\n",
    "    # Randomly select up to 100 indices within this range\n",
    "    # Here we are careful to only take as many indices as are available if there are fewer than 100\n",
    "    selected_indices = rng.choice(in_range_indices, size= bin_size, replace=False)\n",
    "    # selected_indices=selected_indices.reshape()\n",
    "    # Extend the subset_indices list with the selected indices\n",
    "    if (i==0):\n",
    "        subset_indices=selected_indices\n",
    "    else:\n",
    "        subset_indices=np.vstack([subset_indices,selected_indices])\n",
    "# subset_indices.shape\n",
    "# Using the selected indices, we can now reference the corresponding rows from X\n",
    "inducing_variable = X_train[subset_indices.flatten(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c3d371-4e5a-45aa-a7bb-bd0a880c5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inducing_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47374a40-d1c5-4ec5-81ba-1493d339c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 14:52:46.017934: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-04-18 14:52:46.018010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bm4): /proc/driver/nvidia/version does not exist\n",
      "2024-04-18 14:52:46.022035: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = gpflow.models.SGPR(\n",
    "    (X, Y),\n",
    "    kernel=gpflow.kernels.RBF(),\n",
    "    # kernel=gpflow.kernels.SquaredExponential(),\n",
    "    inducing_variable=inducing_variable,\n",
    "        # noise_variance=1.0  # Set to some reasonable initial value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895c39ff-f09b-42e9-affe-18f63b06f4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SGPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>1.0                                                 </td></tr>\n",
       "<tr><td>SGPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>1.0                                                 </td></tr>\n",
       "<tr><td>SGPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>1.0                                                 </td></tr>\n",
       "<tr><td>SGPR.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(72, 8)</td><td>float64</td><td>[[-1.29500000e+00, 1.20389000e+00, 9.85975007e-01...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(gpflow.utilities.print_summary(model, \"notebook\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a8ad6de-5bd4-4ed7-be44-cfdc41fd1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Elapsed time: 0.02 minutes\n",
      "100\n",
      "Elapsed time: 2.16 minutes\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "start_time = time.time()\n",
    "# Instantiate an Adam optimizer with a set learning rate\n",
    "adam_optimizer = tf.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "# Run the optimization loop\n",
    "# Perform a number of optimization steps\n",
    "num_iterations = 200  # Choose an appropriate number of iterations for your problem\n",
    "for i in range(num_iterations):\n",
    "    adam_optimizer.minimize(model.training_loss, model.trainable_variables)\n",
    "    if (i % 100 ==0):\n",
    "        print(i)\n",
    "        elapsed_time_minutes = (time.time() - start_time) / 60\n",
    "        print(f\"Elapsed time: {elapsed_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f6f2026-6ccc-4963-a9d0-9467aeedd48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf41335-cf28-4ea4-b297-f1a49db54fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value                                                 </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SGPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>10.20754                                              </td></tr>\n",
       "<tr><td>SGPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>12.64812                                              </td></tr>\n",
       "<tr><td>SGPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>7.36865                                               </td></tr>\n",
       "<tr><td>SGPR.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(72, 8)</td><td>float64</td><td>[[-2.38590000e+00, -8.24101000e+00, -4.74807000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "INFO:tensorflow:Assets written to: /home/smmrrr/TEM_Analysis/TEM_Analysis/models/test_gp/assets\n"
     ]
    }
   ],
   "source": [
    "print(gpflow.utilities.print_summary(model, \"notebook\"))\n",
    "###save model\n",
    "model.compiled_predict_f = tf.function(\n",
    "    lambda Xnew: model.predict_f(Xnew, full_cov=False),\n",
    "    input_signature=[tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float64)],\n",
    ")\n",
    "model.compiled_predict_y = tf.function(\n",
    "    lambda Xnew: model.predict_y(Xnew, full_cov=False),\n",
    "    input_signature=[tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float64)],\n",
    ")\n",
    "\n",
    "save_dir = \"/home/smmrrr/TEM_Analysis/TEM_Analysis/models/\"\n",
    "save_name = \"test_gp\"\n",
    "tf.saved_model.save(model, save_dir+save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f53ff7d-1700-457a-b68c-c0372835b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = tf.saved_model.load( save_dir+save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca24128-0790-40bc-a809-6aa324c56293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  1810.696518832884\n",
      "Test R2:  0.060971960982251994\n"
     ]
    }
   ],
   "source": [
    "mean, var =  model.predict_y(\n",
    "X_test\n",
    ")\n",
    "\n",
    "Y_pred = mean.numpy().flatten()\n",
    "# Y_test = np.array(model_data.loc[model_data['year'].between(1950,2020),'monthly_mean_ratio'])\n",
    "\n",
    "# Calculate the sum of squares of residuals\n",
    "SS_res = np.sum((Y_test - Y_pred) ** 2)\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "SS_tot = np.sum((Y_test - np.mean(Y_test)) ** 2)\n",
    "rmse = np.sqrt(SS_res/len(Y_test))\n",
    "# Calculate the R² score\n",
    "r2_score = 1 - (SS_res / SS_tot)\n",
    "print(\"Test RMSE: \",rmse)\n",
    "print(\"Test R2: \",r2_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a13818ba-3cd5-4104-9fef-aa605099d7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE:  2753.2375472308922\n",
      "Train R2:  0.06238171334554565\n"
     ]
    }
   ],
   "source": [
    "mean, var = model.predict_y(\n",
    "#     np.array(\n",
    "#      model_data.loc[model_data['year'].between(1950,2020),[['tmp_ratio', 'co2_ratio', 'ordinal_stand_age']]]\n",
    "# )\n",
    "X_train\n",
    ")\n",
    "\n",
    "Y_pred = mean.numpy().flatten()\n",
    "# Y_test = np.array(model_data.loc[model_data['year'].between(1950,2020),'monthly_mean_ratio'])\n",
    "\n",
    "# Calculate the sum of squares of residuals\n",
    "SS_res = np.sum((Y_train - Y_pred) ** 2)\n",
    "\n",
    "# Calculate the total sum of squares\n",
    "SS_tot = np.sum((Y_train - np.mean(Y_train)) ** 2)\n",
    "rmse = np.sqrt(SS_res/len(Y_test))\n",
    "# Calculate the R² score\n",
    "r2_score = 1 - (SS_res / SS_tot)\n",
    "print(\"Train RMSE: \",rmse)\n",
    "print(\"Train R2: \",r2_score)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaforge",
   "language": "python",
   "name": "condaforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
