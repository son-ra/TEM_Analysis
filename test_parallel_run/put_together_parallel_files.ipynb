{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f9ac462-ccbb-4a05-a3c8-c9a3735342f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import cftime \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import cartopy.crs as ccrs\n",
    "import metpy  \n",
    "import calendar\n",
    "import argparse\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a1f0af-ea35-4df4-867c-4be85e440eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/smmrrr/TEM/TEM_Runs/parallel_new_input\n"
     ]
    }
   ],
   "source": [
    "run = 'parallel_new_input'\n",
    "os.chdir('/home/smmrrr/TEM/TEM_Runs/'+run)\n",
    "\n",
    "print(os.getcwd()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad30269-733c-4f01-9c9f-c88ca735619b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "output_paths = glob.glob('*.csv*')\n",
    "input_paths = glob.glob('*.HVD*')\n",
    "\n",
    "print(len(output_paths))\n",
    "print(len(input_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8316e28a-da67-4115-89b8-aba69ce30c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(output_paths))\n",
    "print(len(output_group))\n",
    "print(len(output_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43dc851b-29fa-4c9b-842f-036fe9daee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'C', 'D', 'E', 'I', 'L', 'P', 'R', 'S', 'T', 'V'], dtype='<U1')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(output_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e837a58-06b8-48ca-a043-21ef5b83c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_col_names = ['lon'\n",
    ",'lat'\n",
    ",'variable'\n",
    ",'cohort_number'\n",
    ",'stand_age'\n",
    ",'potential_veg'\n",
    ",'current_veg'\n",
    ",'subtype'\n",
    ",'community_type'\n",
    ",'lc_state'\n",
    ",'silt_clay'\n",
    ",'QC_Value'\n",
    ",'land_area'\n",
    ",'cohort_area'\n",
    ",'year'\n",
    ",'annual_sum'\n",
    ",'monthly_maximum'\n",
    ",'monthly_mean'\n",
    ",'monthly_minimum'\n",
    ",'Jan'\n",
    ",'Feb'\n",
    ",'Mar'\n",
    ",'Apr'\n",
    ",'May'\n",
    ",'Jun'\n",
    ",'Jul'\n",
    ",'Aug'\n",
    ",'Sep'\n",
    ",'Oct'\n",
    ",'Nov'\n",
    ",'Dec'\n",
    ",'region']\n",
    "\n",
    "input_col_names = [\"lon\", 'lat','var' ,'Area', 'year', 'sum', 'max', 'average'\n",
    "         , 'min', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct'\n",
    "         , 'Nov', 'Dec', 'Area_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5107708f-7ae8-4167-a58c-9ce18b24dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_group = [re.findall('[0-9]+$', w) for w in output_paths]\n",
    "output_group = [item for sublist in output_group for item in sublist]\n",
    "\n",
    "output_var = [re.findall('AVLN|NCE|NPP|SOLC|VEGC|GPP|NEP|SMOIST|SOLN|VEGN', w) for w in output_paths]\n",
    "output_var = [item for sublist in output_var for item in sublist]\n",
    "\n",
    "input_group = [re.findall('[0-9]+$', w) for w in input_paths]\n",
    "input_group = [item.upper() for sublist in input_group for item in sublist]\n",
    "\n",
    "input_var = [re.findall('PREC|CLDS|PAR|TAIR|VPR', w) for w in input_paths]\n",
    "input_var = [item for sublist in input_var for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b1ad11-8076-4aa3-8be3-345c8df51305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AVLN', 'GPP', 'NCE', 'NEP', 'NPP', 'SMOIST', 'SOLC', 'SOLN',\n",
       "       'VEGC', 'VEGN'], dtype='<U6')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6a9aa6-0997-4354-94f9-79fa29d33dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9d019f-4003-4048-b5e9-e0787ab6c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make tables with the relevant read in info\n",
    "\n",
    "input_data = pd.DataFrame(\n",
    "{'input_paths': input_paths,\n",
    "'input_group': input_group,\n",
    " 'input_var': input_var\n",
    "}\n",
    ")\n",
    "\n",
    "output_data = pd.DataFrame(\n",
    "{'output_paths': output_paths,\n",
    "'output_group': output_group,\n",
    " 'output_var': output_var\n",
    "}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9c22805-0402-42eb-9efe-1ce58ebd4f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_paths</th>\n",
       "      <th>input_group</th>\n",
       "      <th>input_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CLDS.HVD544</td>\n",
       "      <td>544</td>\n",
       "      <td>CLDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAR.HVD2244</td>\n",
       "      <td>2244</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TAIR.HVD2720</td>\n",
       "      <td>2720</td>\n",
       "      <td>TAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAR.HVD2040</td>\n",
       "      <td>2040</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>952</td>\n",
       "      <td>PREC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>VPR.HVD1360</td>\n",
       "      <td>1360</td>\n",
       "      <td>VPR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>CLDS.HVD1700</td>\n",
       "      <td>1700</td>\n",
       "      <td>CLDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>TAIR.HVD1292</td>\n",
       "      <td>1292</td>\n",
       "      <td>TAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>TAIR.HVD3196</td>\n",
       "      <td>3196</td>\n",
       "      <td>TAIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>PAR.HVD408</td>\n",
       "      <td>408</td>\n",
       "      <td>PAR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      input_paths input_group input_var\n",
       "0     CLDS.HVD544         544      CLDS\n",
       "1     PAR.HVD2244        2244       PAR\n",
       "2    TAIR.HVD2720        2720      TAIR\n",
       "3     PAR.HVD2040        2040       PAR\n",
       "4     PREC.HVD952         952      PREC\n",
       "..            ...         ...       ...\n",
       "245   VPR.HVD1360        1360       VPR\n",
       "246  CLDS.HVD1700        1700      CLDS\n",
       "247  TAIR.HVD1292        1292      TAIR\n",
       "248  TAIR.HVD3196        3196      TAIR\n",
       "249    PAR.HVD408         408       PAR\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81ca7312-4f6a-4bf4-9873-6b9fdb3eb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data = pd.pivot(input_data, index = 'input_group', columns = 'input_var', values = 'input_paths').reset_index()\n",
    "\n",
    "read_in_data = input_data.merge(output_data, left_on = 'input_group', right_on = 'output_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2c2206b-98b0-4e5b-8f76-991951c1ec45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_group</th>\n",
       "      <th>CLDS</th>\n",
       "      <th>PAR</th>\n",
       "      <th>PREC</th>\n",
       "      <th>TAIR</th>\n",
       "      <th>VPR</th>\n",
       "      <th>output_paths</th>\n",
       "      <th>output_group</th>\n",
       "      <th>output_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CLDS.HVD0</td>\n",
       "      <td>PAR.HVD0</td>\n",
       "      <td>PREC.HVD0</td>\n",
       "      <td>TAIR.HVD0</td>\n",
       "      <td>VPR.HVD0</td>\n",
       "      <td>SOLN_LULCC.csv0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CLDS.HVD0</td>\n",
       "      <td>PAR.HVD0</td>\n",
       "      <td>PREC.HVD0</td>\n",
       "      <td>TAIR.HVD0</td>\n",
       "      <td>VPR.HVD0</td>\n",
       "      <td>VEGN_LULCC.csv0</td>\n",
       "      <td>0</td>\n",
       "      <td>VEGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>CLDS.HVD0</td>\n",
       "      <td>PAR.HVD0</td>\n",
       "      <td>PREC.HVD0</td>\n",
       "      <td>TAIR.HVD0</td>\n",
       "      <td>VPR.HVD0</td>\n",
       "      <td>NCE_LULCC.csv0</td>\n",
       "      <td>0</td>\n",
       "      <td>NCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CLDS.HVD0</td>\n",
       "      <td>PAR.HVD0</td>\n",
       "      <td>PREC.HVD0</td>\n",
       "      <td>TAIR.HVD0</td>\n",
       "      <td>VPR.HVD0</td>\n",
       "      <td>SMOIST_LULCC.csv0</td>\n",
       "      <td>0</td>\n",
       "      <td>SMOIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>CLDS.HVD0</td>\n",
       "      <td>PAR.HVD0</td>\n",
       "      <td>PREC.HVD0</td>\n",
       "      <td>TAIR.HVD0</td>\n",
       "      <td>VPR.HVD0</td>\n",
       "      <td>AVLN_LULCC.csv0</td>\n",
       "      <td>0</td>\n",
       "      <td>AVLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>952</td>\n",
       "      <td>CLDS.HVD952</td>\n",
       "      <td>PAR.HVD952</td>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>TAIR.HVD952</td>\n",
       "      <td>VPR.HVD952</td>\n",
       "      <td>AVLN_LULCC.csv952</td>\n",
       "      <td>952</td>\n",
       "      <td>AVLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>952</td>\n",
       "      <td>CLDS.HVD952</td>\n",
       "      <td>PAR.HVD952</td>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>TAIR.HVD952</td>\n",
       "      <td>VPR.HVD952</td>\n",
       "      <td>NCE_LULCC.csv952</td>\n",
       "      <td>952</td>\n",
       "      <td>NCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>952</td>\n",
       "      <td>CLDS.HVD952</td>\n",
       "      <td>PAR.HVD952</td>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>TAIR.HVD952</td>\n",
       "      <td>VPR.HVD952</td>\n",
       "      <td>SOLN_LULCC.csv952</td>\n",
       "      <td>952</td>\n",
       "      <td>SOLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>952</td>\n",
       "      <td>CLDS.HVD952</td>\n",
       "      <td>PAR.HVD952</td>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>TAIR.HVD952</td>\n",
       "      <td>VPR.HVD952</td>\n",
       "      <td>NEP_LULCC.csv952</td>\n",
       "      <td>952</td>\n",
       "      <td>NEP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>952</td>\n",
       "      <td>CLDS.HVD952</td>\n",
       "      <td>PAR.HVD952</td>\n",
       "      <td>PREC.HVD952</td>\n",
       "      <td>TAIR.HVD952</td>\n",
       "      <td>VPR.HVD952</td>\n",
       "      <td>SOLC_LULCC.csv952</td>\n",
       "      <td>952</td>\n",
       "      <td>SOLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    input_group         CLDS         PAR         PREC         TAIR  \\\n",
       "0             0    CLDS.HVD0    PAR.HVD0    PREC.HVD0    TAIR.HVD0   \n",
       "1             0    CLDS.HVD0    PAR.HVD0    PREC.HVD0    TAIR.HVD0   \n",
       "2             0    CLDS.HVD0    PAR.HVD0    PREC.HVD0    TAIR.HVD0   \n",
       "3             0    CLDS.HVD0    PAR.HVD0    PREC.HVD0    TAIR.HVD0   \n",
       "4             0    CLDS.HVD0    PAR.HVD0    PREC.HVD0    TAIR.HVD0   \n",
       "..          ...          ...         ...          ...          ...   \n",
       "495         952  CLDS.HVD952  PAR.HVD952  PREC.HVD952  TAIR.HVD952   \n",
       "496         952  CLDS.HVD952  PAR.HVD952  PREC.HVD952  TAIR.HVD952   \n",
       "497         952  CLDS.HVD952  PAR.HVD952  PREC.HVD952  TAIR.HVD952   \n",
       "498         952  CLDS.HVD952  PAR.HVD952  PREC.HVD952  TAIR.HVD952   \n",
       "499         952  CLDS.HVD952  PAR.HVD952  PREC.HVD952  TAIR.HVD952   \n",
       "\n",
       "            VPR       output_paths output_group output_var  \n",
       "0      VPR.HVD0    SOLN_LULCC.csv0            0       SOLN  \n",
       "1      VPR.HVD0    VEGN_LULCC.csv0            0       VEGN  \n",
       "2      VPR.HVD0     NCE_LULCC.csv0            0        NCE  \n",
       "3      VPR.HVD0  SMOIST_LULCC.csv0            0     SMOIST  \n",
       "4      VPR.HVD0    AVLN_LULCC.csv0            0       AVLN  \n",
       "..          ...                ...          ...        ...  \n",
       "495  VPR.HVD952  AVLN_LULCC.csv952          952       AVLN  \n",
       "496  VPR.HVD952   NCE_LULCC.csv952          952        NCE  \n",
       "497  VPR.HVD952  SOLN_LULCC.csv952          952       SOLN  \n",
       "498  VPR.HVD952   NEP_LULCC.csv952          952        NEP  \n",
       "499  VPR.HVD952  SOLC_LULCC.csv952          952       SOLC  \n",
       "\n",
       "[500 rows x 9 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f02106e-a211-47af-bf5b-bf4d73fe4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_in_data = read_in_data.loc[read_in_data['output_var'] == 'NEP'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f49cf7c-3994-49da-8b88-f25e226b81bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                        7\n",
       "input_group                  0\n",
       "CLDS                 CLDS.HVD0\n",
       "PAR                   PAR.HVD0\n",
       "PREC                 PREC.HVD0\n",
       "TAIR                 TAIR.HVD0\n",
       "VPR                   VPR.HVD0\n",
       "output_paths    NEP_LULCC.csv0\n",
       "output_group                 0\n",
       "output_var                 NEP\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e283b8a-6896-4409-b046-5e59d08a3646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smmrrr/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1207: UserWarning: You are merging on int and float columns where the float values are not equal to their int representation.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_54929/1313626318.py:159: FutureWarning: Dropping invalid columns in SeriesGroupBy.agg is deprecated. In a future version, a TypeError will be raised. Before calling .agg, select only columns which should be valid for the function.\n",
      "  merged_dataset_annual_loop = agg_cohort_output.groupby([\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m land_area \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39maverage(x, weights\u001b[38;5;241m=\u001b[39magg_cohort_output\u001b[38;5;241m.\u001b[39mloc[x\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mland_area\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     merged_dataset_annual_loop \u001b[38;5;241m=\u001b[39m \u001b[43magg_cohort_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcurrent_veg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstand_age\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcohort_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcohort_area\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_area\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mland_area\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                                                                  \u001b[49m\u001b[43mNCE_weighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNCE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcohort_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mprec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mpar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mtair\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtair\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mclds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m                                                                               \u001b[49m\u001b[43mvpr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvpr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mland_area\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     merged_dataset_annual_loop \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([merged_dataset_annual_loop,\n\u001b[1;32m    171\u001b[0m                           agg_cohort_output\u001b[38;5;241m.\u001b[39mgroupby([\n\u001b[1;32m    172\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_veg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstand_age\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(cohort_area\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcohort_area\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m), total_area\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mland_area\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m                                                                                clds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclds\u001b[39m\u001b[38;5;124m'\u001b[39m, land_area),\n\u001b[1;32m    178\u001b[0m                                                                                vpr \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvpr\u001b[39m\u001b[38;5;124m'\u001b[39m, land_area))])\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/generic.py:869\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[1;32m    868\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args, kwargs)\n\u001b[0;32m--> 869\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/apply.py:168\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(arg):\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/apply.py:481\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    478\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    482\u001b[0m         key: obj\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    483\u001b[0m     }\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[1;32m    486\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/apply.py:482\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    478\u001b[0m     results \u001b[38;5;241m=\u001b[39m {key: colg\u001b[38;5;241m.\u001b[39magg(how) \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m    481\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 482\u001b[0m         key: \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    483\u001b[0m     }\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# set the final keys\u001b[39;00m\n\u001b[1;32m    486\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(arg\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/generic.py:271\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n\u001b[0;32m--> 271\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n\u001b[1;32m    274\u001b[0m         \u001b[38;5;66;03m# \"Optional[List[str]]\", variable has type \"Index\")\u001b[39;00m\n\u001b[1;32m    275\u001b[0m         ret\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m columns  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/generic.py:326\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[1;32m    325\u001b[0m     key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m--> 326\u001b[0m     results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/generic.py:284\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, cyfunc)()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrouper\u001b[38;5;241m.\u001b[39mnkeys \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1499\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     output[key] \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output:\n\u001b[0;32m-> 1499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_apply_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selected_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1464\u001b[0m, in \u001b[0;36mGroupBy._python_apply_general\u001b[0;34m(self, f, data, not_indexed_same)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_apply_general\u001b[39m(\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m     not_indexed_same: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03m    Apply function f in python space\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;124;03m        data after applying f\u001b[39;00m\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1464\u001b[0m     values, mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m not_indexed_same \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1467\u001b[0m         not_indexed_same \u001b[38;5;241m=\u001b[39m mutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmutated\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/ops.py:761\u001b[0m, in \u001b[0;36mBaseGrouper.apply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;66;03m# group might be modified\u001b[39;00m\n\u001b[1;32m    760\u001b[0m group_axes \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39maxes\n\u001b[0;32m--> 761\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mutated \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_indexed_like(res, group_axes, axis):\n\u001b[1;32m    763\u001b[0m     mutated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:1476\u001b[0m, in \u001b[0;36mGroupBy._python_agg_general.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_python_agg_general\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1475\u001b[0m     func \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mis_builtin_func(func)\n\u001b[0;32m-> 1476\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;66;03m# iterate through \"columns\" ex exclusions to populate output dict\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m     output: \u001b[38;5;28mdict\u001b[39m[base\u001b[38;5;241m.\u001b[39mOutputKey, ArrayLike] \u001b[38;5;241m=\u001b[39m {}\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# agg_cohort_output.to_csv(ouput_data_path+'merged_dataset_'+read_in_data.loc[i, 'output_group']+'.csv', index=False)\u001b[39;00m\n\u001b[1;32m    151\u001b[0m agg_cohort_output\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m--> 153\u001b[0m cohort_area \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magg_cohort_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcohort_area\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\u001b[39;00m\n\u001b[1;32m    154\u001b[0m land_area \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39maverage(x, weights\u001b[38;5;241m=\u001b[39magg_cohort_output\u001b[38;5;241m.\u001b[39mloc[x\u001b[38;5;241m.\u001b[39mindex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mland_area\u001b[39m\u001b[38;5;124m\"\u001b[39m])  \u001b[38;5;66;03m# https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/condaforge/lib/python3.10/site-packages/numpy/lib/function_base.py:550\u001b[0m, in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(scl \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m):\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights sum to zero, can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be normalized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 550\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwgt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeepdims_kw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscl\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returned:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scl\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m avg\u001b[38;5;241m.\u001b[39mshape:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "## TEM PFT info\n",
    "# forest_vegs = [9, 4, 16, 33, 19, 10 ]\n",
    "# forest_veg_names = ['needle-leaf evergreen temperate','boreal','broadleaved evergreen tree tropical'\n",
    "#                    ,'broadleaved evergreen tree temperate','broadleaved deciduous tree tropical'\n",
    "#                    ,'broadleaved deciduous tree temperate']\n",
    "\n",
    "\n",
    "ouput_data_path = '/home/smmrrr/TEM_Analysis/test_parallel_run/'\n",
    "\n",
    "# for i in range(len(read_in_data)):\n",
    "for i in range(len(read_in_data)):\n",
    "\n",
    "###read in cohort output\n",
    "    cohort_output = pd.read_csv(read_in_data.loc[i, 'output_paths']\n",
    "                , names = output_col_names)\n",
    "\n",
    "    ##read in precipitation files\n",
    "    prec = pd.read_csv(read_in_data.loc[i, 'PREC']\n",
    "               , names = input_col_names)\n",
    "    par = pd.read_csv(read_in_data.loc[i, 'PAR']\n",
    "               , names = input_col_names)\n",
    "    clds = pd.read_csv(read_in_data.loc[i, 'CLDS']\n",
    "               , names = input_col_names)\n",
    "    tair = pd.read_csv(read_in_data.loc[i, 'TAIR']\n",
    "               , names = input_col_names)\n",
    "    vpr = pd.read_csv(read_in_data.loc[i, 'VPR']\n",
    "               , names = input_col_names)\n",
    "\n",
    "\n",
    "    ## shape input datasets wide to long\n",
    "    prec = pd.melt(prec, id_vars = ['lon','lat', 'Area', 'year'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='prec'\n",
    "            ,col_level=0)\n",
    "\n",
    "    par = pd.melt(par, id_vars = ['lon','lat', 'Area', 'year'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='par'\n",
    "            ,col_level=0)\n",
    "\n",
    "    clds = pd.melt(clds, id_vars = ['lon','lat', 'Area', 'year'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='clds'\n",
    "            ,col_level=0)\n",
    "\n",
    "    tair = pd.melt(tair, id_vars = ['lon','lat', 'Area', 'year'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='tair'\n",
    "            ,col_level=0)\n",
    "    \n",
    "    vpr = pd.melt(vpr, id_vars = ['lon','lat', 'Area', 'year'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='vpr'\n",
    "            ,col_level=0)\n",
    "\n",
    "    ##merge climate variables together\n",
    "    climate_vars = prec.merge(\n",
    "                par,on = ['lon','lat', 'Area', 'year', 'month']\n",
    "                ).merge(\n",
    "                tair ,on = ['lon','lat', 'Area', 'year', 'month']                           \n",
    "                ).merge(\n",
    "                clds ,on = ['lon','lat', 'Area', 'year', 'month']                           \n",
    "                ).merge(\n",
    "                vpr ,on = ['lon','lat', 'Area', 'year', 'month']                           \n",
    "                )\n",
    "\n",
    "    ##subset to forest veg types \n",
    "    # cohort_output = cohort_output.loc[cohort_output['current_veg'].isin(forest_vegs)] \n",
    "\n",
    "    ##melt cohort output\n",
    "    cohort_output = pd.melt(cohort_output, id_vars = ['lon','lat', 'cohort_area', 'land_area', 'year', 'current_veg', 'stand_age'], value_vars = [\n",
    "    'Jan',\n",
    "    'Feb',\n",
    "    'Mar',\n",
    "    'Apr',\n",
    "    'May',\n",
    "    'Jun',\n",
    "    'Jul',\n",
    "    'Aug',\n",
    "    'Sep',\n",
    "    'Oct',\n",
    "    'Nov',\n",
    "    'Dec'], \n",
    "             var_name='month', value_name='NCE'\n",
    "            ,col_level=0)\n",
    "\n",
    "\n",
    "    agg_cohort_output = cohort_output.merge(\n",
    "                climate_vars, how = 'left'\n",
    "        ,on = ['lon','lat', 'year', 'month']\n",
    "                )\n",
    "\n",
    "\n",
    "    \n",
    "    # agg_cohort_output.to_csv(ouput_data_path+'merged_dataset_'+read_in_data.loc[i, 'output_group']+'.csv', index=False)\n",
    "    agg_cohort_output.count()\n",
    "\n",
    "    cohort_area = lambda x: np.average(x, weights=agg_cohort_output.loc[x.index, \"cohort_area\"])  # https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\n",
    "    land_area = lambda x: np.average(x, weights=agg_cohort_output.loc[x.index, \"land_area\"])  # https://stackoverflow.com/questions/31521027/groupby-weighted-average-and-sum-in-pandas-dataframe\n",
    "\n",
    "    if (i==0):\n",
    "\n",
    "\n",
    "        merged_dataset_annual_loop = agg_cohort_output.groupby([\n",
    "                'month','year','current_veg', 'stand_age']).agg(cohort_area=('cohort_area', 'sum'), total_area=('land_area', 'sum'),\n",
    "                                                                                      NCE_weighted=('NCE', cohort_area), \n",
    "                                                                                   prec = ('prec', land_area),\n",
    "                                                                                   par = ('par', land_area),\n",
    "                                                                                   tair = ('tair', land_area),\n",
    "                                                                                   clds = ('clds', land_area),\n",
    "                                                                                   vpr = ('vpr', land_area))\n",
    "                                                                                    \n",
    "    else:\n",
    "                                                        \n",
    "        merged_dataset_annual_loop = pd.concat([merged_dataset_annual_loop,\n",
    "                              agg_cohort_output.groupby([\n",
    "                'month','year','current_veg', 'stand_age']).agg(cohort_area=('cohort_area', 'sum'), total_area=('land_area', 'sum'),\n",
    "                                                                                      NCE_weighted=('NCE', cohort_area), \n",
    "                                                                                   prec = ('prec', land_area),\n",
    "                                                                                   par = ('par', land_area),\n",
    "                                                                                   tair = ('tair', land_area),\n",
    "                                                                                   clds = ('clds', land_area),\n",
    "                                                                                   vpr = ('vpr', land_area))])\n",
    "   \n",
    "    merged_dataset_annual_loop.to_csv(ouput_data_path+'merged_dataset_annual_loop.csv')\n",
    "    print(i)\n",
    "    print(merged_dataset_annual_loop.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f3ddd-bab2-47db-bde4-83b4240a8a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b186a0e-0c82-407b-910e-93c03cd12583",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_output.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaforge",
   "language": "python",
   "name": "condaforge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
